{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "import urllib\n",
    "import regex as re\n",
    "\n",
    "\n",
    "# train data extraction\n",
    "\n",
    "train_df = pd.read_csv('csvs/mle-1-assign-dataset - train_data.csv')\n",
    "\n",
    "print(train_df.describe)\n",
    "\n",
    "print('Total no.of target categories: ', train_df['target_col'].unique().tolist())\n",
    "print('Total no.of training data =', len(train_df))\n",
    "\n",
    "for group_name, grp_df in train_df.groupby(by='target_col'):\n",
    "    print(group_name, f'-> total no.of occurances in this category: {len(grp_df)}')\n",
    "\n",
    "\n",
    "# train_df['datasheet_link'].dropna(inplace= True)\n",
    "# train_df['datasheet_link'].drop('-', inplace= True)\n",
    "train_data_links = train_df['datasheet_link'].to_list()\n",
    "\n",
    "unique_train_data_links = list(set(train_data_links))\n",
    "\n",
    "target_cols = []\n",
    "for link in unique_train_data_links:\n",
    "    target_cols.append(train_df.loc[train_df['datasheet_link'] == link, 'target_col'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 'abc/'\n",
    "\n",
    "b.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in unique_train_data_links:\n",
    "\n",
    "    if link.endswith('/'):\n",
    "        print(link)\n",
    "        print('_'.join(link.split('/')[-3:])[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'https://www.acuitybrands.com/api/products/getasset/holophane/1649334/bcfca2cf-282b-4dbf-a58a-a8e3e6b993d6/holophane-care222-hldmps-cylinder-pendant-with-stem.pdf?abl_version=01%2f12%2f2023+16%3a53%3a44&DOC_Type=SPEC_SHEET'\n",
    "\n",
    "\n",
    "def clean_filename(url):\n",
    "    # Parse the URL\n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    \n",
    "    # Extract the path component\n",
    "    path = parsed_url.path\n",
    "    \n",
    "    # Extract the filename from the path\n",
    "    filename = path.split('/')[-1]\n",
    "    \n",
    "    # Decode any percent-encoded characters\n",
    "    filename = urllib.parse.unquote(filename)\n",
    "    print(filename)\n",
    "    # Clean the filename: remove unwanted characters and extra spaces\n",
    "    filename = re.sub(r'[^\\w\\s.-]', '', filename)  # Remove special characters\n",
    "    filename = re.sub(r'\\s+', ' ', filename)       # Replace multiple spaces with a single space\n",
    "    filename = filename.strip()                    # Remove leading and trailing spaces\n",
    "    \n",
    "    return filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holophane-care222-hldmps-cylinder-pendant-with-stem.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'holophane-care222-hldmps-cylinder-pendant-with-stem.pdf'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_filename(s.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col_links = [[1,2], [3,4]]\n",
    "\n",
    "new_tr_df  = pd.DataFrame(target_col_links, columns= ['url', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url  target\n",
       "0    1       2\n",
       "1    3       4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1266"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "len(os.listdir('data/train_simple'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "input_dir = '/Users/guest1/Desktop/parspec-assignment/data/test'\n",
    "text_dir = '/Users/guest1/Desktop/parspec-assignment/data/test_texts'\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(text_dir, exist_ok=True)\n",
    "\n",
    "files = os.listdir(input_dir)\n",
    "\n",
    "for file in files:\n",
    "    if file.lower().endswith('.pdf'):\n",
    "        print(f'Processing {file}...')\n",
    "        text = ''\n",
    "        try:\n",
    "            loader = PyPDFLoader(os.path.join(input_dir, file))\n",
    "            pages = loader.load_and_split()\n",
    "            for page in pages:\n",
    "                text += page.page_content\n",
    "            \n",
    "            output_file = os.path.join(text_dir, file.replace('.pdf', '.txt'))\n",
    "            with open(output_file, 'wb') as f:\n",
    "                f.write(text.encode('utf-8'))\n",
    "                f.close()\n",
    "            print(f'The text of {file} has been extracted successfully.')\n",
    "        except Exception as e:\n",
    "            print(f'Failed to process {file}. Error: {e}')\n",
    "    else:\n",
    "        print(f'Skipping non-PDF file: {file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product:  4694P  \n",
      " \n",
      "4K UHD Coax for 12G-SDI, 75 Ohm, RG-6, 18 AWG Solid SC, Foil + 95% TC\n",
      "Braid, PVC Jkt, CMP\n",
      "Product Description\n",
      "75 Ohm SDI Coax, RG-6, 18 AWG Solid Silvered Copper Conductor, FEP Insulation, Foil + 95% Tinned Copper Braid Shield, PVC Jacket, CMP\n",
      "Technical Specifications\n",
      "Product Overview\n",
      "Suitable Applications: Ultra-High Definition Digital Video, 4K Single-link 12 Gb/s UHDTV, 4K D-Cinema, 8K Quad-link UHDTV, HD-SDI 1080p\n",
      "Construction Details\n",
      "RG Type: 6\n",
      "Conductor\n",
      "Size Stranding Nom. Diameter Material\n",
      "18 AWG Solid 0.040 in SC - Silvered Copper\n",
      "Insulation\n",
      "Material Nom. Insulation Diameter Color Code\n",
      "FEP - Fluorinated Ethylene Propylene (Foam) 0.168 in (4.27 mm) White\n",
      "Outer Shield\n",
      "Layer Outer Shield Type Material Material Trade Name Coverage\n",
      "1 Tape Tri-Laminate (Alum+Poly+Alum) DuobondÂ® II 100%\n",
      "2 Braid Tinned Copper (TC) 95%\n",
      "Outer Jacket\n",
      "Material Nom. Diameter\n",
      "PVC - Polyvinyl Chloride 0.229 in (5.82 mm)\n",
      "Overall Cable Diameter (Nominal): 0.229 in (5.82 mm)\n",
      "Electrical Characteristics\n",
      "Return Loss (RL)\n",
      "Frequency Min. Return Loss\n",
      "5 - 1600 MHz 23 dB\n",
      "1600 - 4500 MHz 21 dB\n",
      "4500 - 12000 MHz 15 dB\n",
      "Attenuation\n",
      "Frequency Nom. Attenuation\n",
      "1 MHz 0.23 dB/100ft\n",
      "3.58 MHz 0.46 dB/100ft\n",
      "5 MHz 0.54 dB/100ft\n",
      "6 MHz 0.58 dB/100ft\n",
      "7 MHz 0.63 dB/100ft\n",
      "10 MHz 0.73 dB/100ft\n",
      "12 MHz 0.80 dB/100ft\n"
     ]
    }
   ],
   "source": [
    "print(pages[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMaxConsecutiveOnes(nums: List[int]) -> int:\n",
    "        one_pointer = 0\n",
    "        max_counts = []\n",
    "        for i in range(len(nums)-1):\n",
    "            j = i+1\n",
    "            if nums[i] ==1 and nums[i] ==nums[j]:\n",
    "                one_pointer += 1\n",
    "            elif nums[i] == 1 and nums[i] != nums[j]:\n",
    "               one_pointer = 0\n",
    "\n",
    "            \n",
    "            max_counts.append(one_pointer)\n",
    "\n",
    "        if max(max_counts) > 0:\n",
    "             max_ = max(max_counts)+1\n",
    "        else:\n",
    "             max_ = max(max_counts)\n",
    "\n",
    "        return max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findMaxConsecutiveOnes([0,0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('data/train_texts'):\n",
    "    if file.endswith('.pdf'):\n",
    "        os.remove(os.path.join('data/train_texts', file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1138"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('data/train_texts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description RG RG type RF cables RG, Ohm, GHz, C, Ã¸ mm, PVC jacket Technical Data Construction Material Detail Diameter Centre conductor Steel, Copper plated Strand- mm Dielectric PE Polyethylene mm Outer conductor Copper, Tin plated Braid, mm Jacket PVC II low migration RAL- bk mm- Print HUBERSUHNER RG U Ohm production order number Electrical Data Impedance Î©- Operating Frequency GHz Capacitance pFm Velocity of signal propagation Signal delay nsm Screening ef fectiveness dB up to GHz Operating voltage kV rmsat sea level Test voltage kVrms Hz min Mechanical Data Weight kg m Min. bending radius static mm mm Environmental Data Temperature range- C... C Installation temperature- C... C Halogen free No EU RoHS- including and compliant EC REACH compliant Additional Information MIL reference M- former reference M-RG Remarks For details refer to the HUBERSUHNER RF CABLES GENERAL CA TALOGUE or contact your nearest HUBERSUHNER partner Suitable Connectors Cable group U mm OhmData Sheet Flexible RF cable RG__U Item Page Document DOC- AT PDO O date of publication. uncontrolled copyMatrix typical Attenuation formula af bf and maximum Power CW formula pf Coef ficients a b fmax P at GHz Frequency Nom. attenuation Nom. attenuation Max. CW power GHz dB m dB ft W sea level C ambient temperaturesea level C ambient temperaturesea level C ambient temperature,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, www.hubersuhner.com HUBERSUHNER is certified according to ISO, ISO, ASEN, ISOTS and IRIS. Waiver Fact and figures herein are for information only and do not represent any warranty of any kind.Data Sheet Flexible RF cable RG__U Item Page Document DOC- AT PDO O date of publication. uncontrolled copy\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove all numbers and decimal values\n",
    "    text = re.sub(r'\\d+(\\.\\d+)?', '', text)\n",
    "    \n",
    "    # Replace multiple consecutive newlines with a single newline\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    \n",
    "    # Remove special characters and symbols, keep only essential details\n",
    "    # Allow letters, digits, spaces, and common punctuation\n",
    "    text = re.sub(r'[^\\w\\s.,-]', '', text)\n",
    "    \n",
    "    # Remove extra spaces around punctuation and between words\n",
    "    text = re.sub(r'\\s+([.,-])', r'\\1', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "input_text = \"\"\"\n",
    "Description\n",
    "RG: RG type RF cables\n",
    "RG174, 50 Ohm, 1 GHz, 85Â°C, Ã¸2.55 mm, PVC jacket\n",
    "Technical Data\n",
    "Construction\n",
    "Material Detail Diameter\n",
    "Centre conductor Steel, Copper plated Strand-07 0.48 mm\n",
    "Dielectric PE (Polyethylene) 1.48 mm\n",
    "Outer conductor Copper , Tin plated Braid, 87% 2 mm\n",
    "Jacket PVC II (low migration) RAL 9005 - bk 2.55 mm +/- 0.13\n",
    "Print: HUBER+SUHNER RG 174 U 50 Ohm (production order number)\n",
    "Electrical Data\n",
    "Impedance 50 Î© +/- 2\n",
    "Operating Frequency 1 GHz\n",
    "Capacitance 101 pF/m\n",
    "Velocity of signal propagation 66 %\n",
    "Signal delay 5.03 ns/m\n",
    "Screening ef fectiveness â¥ 40 dB (up to 1 GHz)\n",
    "Operating voltage â¤ 1.5 kV rms(at sea level)\n",
    "Test voltage 3 kVrms(50 Hz/1 min)\n",
    "Mechanical Data\n",
    "Weight 1.12 kg/100 m\n",
    "Min. bending radius static 15 mm\n",
    "26 mm\n",
    "Environmental Data\n",
    "Temperature range -25 Â°C ... +85 Â°C\n",
    "Installation temperature -20 Â°C... +60 Â°C\n",
    "Halogen free No\n",
    "2011/65/EU (RoHS - including\n",
    "2015/863 and 2017/2102)compliant\n",
    "1907/2006/EC (REACH) compliant\n",
    "Additional Information\n",
    "MIL reference: M17/196-00001 (former reference: M17/1 19-RG174)\n",
    "Remarks\n",
    "(For details refer to the HUBER+SUHNER RF CABLES GENERAL CA TALOGUE or contact your nearest HUBER+SUHNER partner)\n",
    "Suitable Connectors\n",
    "Cable group U2 2 mm / 50 OhmData Sheet\n",
    "Flexible RF cable\n",
    "RG_174_/U Item: 22510040\n",
    "Page 1/2 Document: DOC-0000177742 AT / PDO O / date of publication: 14.10.2020 17:27:19 / uncontrolled copyMatrix typical Attenuation [ formula: (a*f^0.5 + b*f) ] and maximum Power CW [ formula: (p/f^0.5) ]\n",
    "Coef ficients:\n",
    "a =0.888 b =0.034 fmax =1 P at 1GHz = 37\n",
    "Frequency Nom. attenuation Nom. attenuation Max. CW power\n",
    "(GHz) (dB / m) (dB / ft) (W)\n",
    "sea level 25Â° C\n",
    "ambient\n",
    "temperaturesea level 25Â° C\n",
    "ambient\n",
    "temperaturesea level 40Â° C\n",
    "ambient\n",
    "temperature\n",
    "0,05 0,2 0,061 165\n",
    "0,1 0,28 0,087 117\n",
    "0,15 0,35 0,106 96\n",
    "0,2 0,4 0,123 83\n",
    "0,25 0,45 0,138 74\n",
    "0,3 0,5 0,151 68\n",
    "0,35 0,54 0,164 63\n",
    "0,4 0,58 0,175 59\n",
    "0,45 0,61 0,186 55\n",
    "0,5 0,64 0,197 52\n",
    "0,55 0,68 0,206 50\n",
    "0,6 0,71 0,216 48\n",
    "0,65 0,74 0,225 46\n",
    "0,7 0,77 0,234 44\n",
    "0,75 0,79 0,242 43\n",
    "0,8 0,82 0,250 41\n",
    "0,85 0,85 0,258 40\n",
    "0,9 0,87 0,266 39\n",
    "0,95 0,9 0,274 38\n",
    "1,0 0,92 0,281 37\n",
    "www .hubersuhner .com HUBER+SUHNER is certified according to ISO 9001, ISO 14001, AS/EN9100, ISO/TS 16949 and IRIS.\n",
    "Waiver: Fact and figures herein are for information only and do not represent any warranty of any kind.Data Sheet\n",
    "Flexible RF cable\n",
    "RG_174_/U Item: 22510040\n",
    "Page 2/2 Document: DOC-0000177742 AT / PDO O / date of publication: 14.10.2020 17:27:19 / uncontrolled copy\n",
    "\"\"\"\n",
    "\n",
    "cleaned_text = clean_text(input_text)\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "text_dir = 'data/train_texts'\n",
    "texts = []\n",
    "main_target_labels = []\n",
    "\n",
    "train_df = pd.read_csv('processed_train_data.csv', sep= '|')\n",
    "# train_df['target_label'] = label_encoder.fit_transform(train_df['target'])\n",
    "\n",
    "\n",
    "for file in os.listdir(text_dir):\n",
    "    if  len(train_df.loc[train_df['file_name'] == file.replace('.txt', '.pdf'), 'target'].values) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        with open(os.path.join(text_dir, file), 'r+') as f:\n",
    "            texts.append(clean_text(f.read()))\n",
    "            main_target_labels.append(train_df.loc[train_df['file_name'] == file.replace('.txt', '.pdf'), 'target'].values[0])\n",
    "        # print(file, train_df.loc[train_df['file_name'] == file.replace('.txt', '.pdf'), 'target'].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'lit', '##tel', '##fus', '##e', 'inc', 'specifications', 'are', 'subject', 'change', 'without', 'notice', 'revised', 'axial', 'lead', 'cartridge', 'fuse', '##s', 'time', 'la', '##g', 'series', 'series', 'sl', '##o', 'b', '##lo', 'fuse', 'with', 'indicating', 'option', 'agency', 'approval', '##s', 'agency', 'agency', 'file', 'number', 'amp', '##ere', 'range', 'cartridge', 'form', 'an', '##b', '##k', 'n', '##b', '##k', 'n', '##b', '##k', 'axial', 'lead', '##ed', 'form', 'an', '##b', '##k', 'n', '##b', '##k', 'n', '##b', '##k', 'af', '##ea', '##tures', 'electrical', 'characteristics', 'for', 'series', 'available', 'cartridge', 'and', 'axial', 'lead', 'form', 'and', 'wide', 'range', 'lead', 'forming', 'dimension', 'and', 'packaging', 'options', 'accordance', 'with', 'csa', 'nm', '##x', 'standard', 'ro', '##hs', 'compliant', 'and', 'lead', 'free', 'tripped', 'fuse', 'indicating', 'option', 'add', 'suffix', 'part', 'number', 'fuse', '##s', 'are', 'available', 'for', 'board', 'wash', '##able', 'with', 'the', 'additional', 'sealing', 'process', 'add', 'suffix', 'part', 'number', 'sleeve', '##d', 'fuse', 'option', 'available', 'contact', 'lit', '##tel', '##fus', '##e', 'for', 'additional', 'information', 'amp', '##ere', 'rating', 'opening', 'time', 'hours', 'minimum', 'hour', 'maximum', 'seconds', 'minimum', 'seconds', 'maximum', '##ro', '##hs', 'p', '##b', '##ps', 'description', 'lit', '##tel', '##fus', '##e', 'series', 'sl', '##o', 'b', '##lo', 'fuse', '##s', 'are', 'available', 'size', 'cartridge', 'axial', 'lead', 'form', 'offer', 'tripped', 'fuse', 'indicating', 'option', 'and', 'offer', 'features', 'designed', 'meet', 'rigorous', 'telecom', 'industry', 'requirements', 'series', 'product', 'ordered', 'with', 'the', 'tripped', 'fuse', 'indicating', 'option', 'show', 'disco', '##lor', '##ation', 'the', 'glass', 'body', 'immediately', 'after', 'trip', 'they', 'offer', 'the', 'same', 'performance', 'characteristics', 'standard', 'product', 'and', 'help', 'reduce', 'time', 'locating', 'the', 'tripped', 'fuse', 'and', 'troubles', '##hoot', '##ing', 'circuit', 'issues', 'the', 'series', 'range', 'combines', 'conventional', 'over', '##cu', '##rre', '##nt', 'protection', 'with', 'ability', 'withstand', 'high', 'current', 'short', 'duration', 'pulses', 'which', 'com', '##pl', '##ies', 'short', 'circuit', 'requirements', 'for', 'telephone', 'equipment', 'ins', '##ulating', 'sleeve', 'option', 'also', 'available', 'e', '##fer', 'the', 'surge', 'withstand', 'specifications', 'section', 'this', 'document', 'for', 'additional', 'information', 'data', '##sh', '##eet', 'samples', 'resources', 'data', '##sh', '##eet', 'samples', 'resources', 'series', 'series', 'series', 'series', 'series', 'series', 'series', '##ad', '##ditional', 'information', 'accessories', 'for', 'recommended', 'fuse', 'accessories', 'for', 'this', 'product', 'series', 'see', 'recommended', 'accessories', 'section', 'lit', '##tel', '##fus', '##e', 'inc', 'specifications', 'are', 'subject', 'change', 'without', 'notice', 'revised', 'axial', 'lead', 'cartridge', 'fuse', '##s', 'time', 'la', '##g', 'series', '##ele', '##ctric', '##al', 'characteristic', 'specification', 'item', 'amp', 'code', '##amp', '##ere', 'rating', 'voltage', 'rating', 'interrupting', 'rating', '##no', '##mina', '##l', 'cold', 'resistance', 'oh', '##ms', 'nominal', 'melting', 'sec', 'agency', 'approval', '##s', 'va', '##c', 'va', '##c', 'v', '##dc', 'va', '##c', 'va', '##c', 'va', '##c', 'v', '##dc', 'va', '##c', 'va', '##c', 'va', '##c', 'v', '##dc', 'va', '##c', 'v', '##dc', 'amp', 'code', 'amp', '##ere', 'rating', 'interrupting', 'rating', '##no', '##mina', '##l', 'cold', 'resistance', 'oh', '##ms', 'nominal', 'melting', 'sec', 'va', '##c', 'va', '##c', 'va', '##c', 'va', '##c', 'peak', 'micro', '##se', '##con', '##ds', 'repetition', '##ss', '##urg', '##e', 'withstand', 'specific', '##aton', '##s', 'peak', 'withstand', 'current', 'these', 'fuse', '##s', 'will', 'withstand', 'repetition', '##s', 'double', 'exponential', 'impulse', 'wave', 'having', 'peak', 'currents', 'and', 'peak', 'voltage', '##s', 'listed', 'lit', '##tel', '##fus', '##e', 'inc', 'specifications', 'are', 'subject', 'change', 'without', 'notice', 'revised', 'axial', 'lead', 'cartridge', 'fuse', '##s', 'time', 'la', '##g', 'series', '##aver', '##age', 'time', 'current', 'curves', 'em', '##per', '##at', '##ure', 'rating', 'curve', 'at', '##ime', 'seconds', 'current', 'amp', '##eres', 'sold', '##ering', 'parameters', 'wave', 'sold', '##ering', 'dwell', 'time', 'time', 'seconds', 'temperature', 'measured', 'bottom', 'side', 'board', 'cooling', 'time', 'pre', '##hea', '##t', 'time', '##wave', 'parameter', 'lead', 'free', 'recommendation', 'pre', '##hea', '##t', 'depends', 'flux', 'activation', 'temperature', 'typical', 'industry', 'recommendation', 'temperature', 'minimum', 'temperature', 'maximum', 'pre', '##hea', '##t', 'time', 'seconds', 'sold', '##er', 'pot', 'temperature', 'maximum', 'sold', '##er', 'dwell', 'time', 'seconds', 'recommended', 'hand', 'sold', '##er', 'parameters', 'sold', '##er', 'iron', 'temperature', 'heating', 'time', 'seconds', 'max', 'note', 'these', 'devices', 'are', 'not', 'recommended', 'for', 'convection', 'ref', '##low', 'process', 'recommended', 'process', 'parameters', 'note', 're', '##rating', 'depicted', 'this', 'curve', 'addition', 'the', 'industry', 'practice', 'der', '##ating', 'for', 'continuous', 'operation', 'lit', '##tel', '##fus', '##e', 'inc', 'specifications', 'are', 'subject', 'change', 'without', 'notice', 'revised', 'axial', 'lead', 'cartridge', 'fuse', '##s', 'time', 'la', '##g', 'series', 'series', 'series', 'ty', '##p', 'materials', '##body', 'glass', 'cap', 'nickel', 'plate', '##d', 'brass', 'leads', 'tin', 'plate', '##d', 'copper', 'er', '##mina', '##l', 'strength', 'mil', 'st', '##d', 'method', 'test', 'condition', 'sold', '##era', '##bility', 'mil', 'st', '##d', 'method', 'product', 'marking', '##cap', 'brand', 'logo', 'current', 'and', 'voltage', 'ratings', 'cap', 'series', 'and', 'agency', 'approval', 'marks', '##pro', '##du', '##ct', 'characteristics', 'operating', 'temperature', 'thermal', 'shock', '##mi', '##l', 'st', '##d', 'method', 'test', 'condition', 'cycles', 'vibration', 'mil', 'st', '##d', 'method', 'humidity', '##mi', '##l', 'st', '##d', 'method', 'test', 'condition', 'high', 'and', 'elevated', 'temperature', 'for', 'hours', 'salt', 'spray', '##mi', '##l', 'st', '##d', 'method', 'test', 'condition', 'dimensions', 'part', 'numbering', 'system', 'xx', '##xx', 'lead', 'free', '##pack', '##aging', 'code', '##qua', '##nti', '##ty', 'code', '##amp', 'codes', '##eries', 'fill', '##er', '##m', 'refer', 'amp', 'code', 'column', 'electrical', 'characteristics', 'table', 'cartridge', 'axial', 'lead', '##ed', 'recommended', 'accessories', 'accessory', 'y', '##pe', 'series', 'description', '##max', 'application', 'voltage', '##max', 'application', 'amp', '##era', '##ge', 'holder', 'panel', 'mount', 'shock', 'safe', 'fuse', '##holder', 'line', 'fuse', '##holder', 'panel', 'mount', 'flip', 'top', 'shock', 'safe', 'fuse', '##holder', 'block', 'om', '##ni', 'b', '##lok', 'fuse', 'block', 'clip', 'board', 'mount', 'fuse', 'clip', 'notes', 'not', 'use', 'applications', 'above', 'rating', 'please', 'refer', 'fuse', '##holder', 'data', 'sheet', 'for', 'specific', 'rating', 'information', 'please', 'contact', 'factory', 'for', 'applications', 'greater', 'than', 'the', 'max', 'voltage', 'and', 'amp', '##era', '##ge', 'shown', 'packaging', 'packaging', 'option', 'packaging', 'specification', 'quantity', '##qua', '##nti', '##ty', 'packaging', 'code', '##t', 'api', '##ng', 'width', 'series', 'bulk', 'bulk', 'v', '##x', '##s', 'bulk', 'lit', '##tel', '##fus', '##e', 'inc', 'specifications', 'are', 'subject', 'change', 'without', 'notice', 'revised', 'axial', 'lead', 'cartridge', 'fuse', '##s', 'time', 'la', '##g', 'series', '##pack', '##aging', 'packaging', 'option', 'packaging', 'specification', 'quantity', '##qua', '##nti', '##ty', 'packaging', 'code', '##t', 'api', '##ng', 'width', 'series', 'con', '##t', 'bulk', 'h', '##x', '##s', 'bulk', 'bulk', 'mx', '##s', 'series', 'bulk', 'bulk', 'v', '##x', '##s', 'bulk', 'bulk', 'h', '##x', '##s', 'bulk', 'bulk', 'mx', '##e', 'bulk', 'mx', '##f', 'bulk', 'mx', '##f', 'bulk', 'mx', '##f', 'bulk', 'mx', '##f', 'bulk', 'mx', '##f', 'bulk', 'mx', '##f', 'bulk', 'mx', '##f', 'bulk', 'mx', '##f', 'bulk', 'mx', '##o', 'bulk', 'mx', '##s', 'reel', 'and', 'tape', 'e', '##ia', 'dr', '##t', 'reel', 'and', 'tape', 'e', '##ia', 'dr', '##t', 'reel', 'and', 'tape', 'e', '##ia', 'dr', '##t', 'reel', 'and', 'tape', 'e', '##ia', 'er', '##t', 'reel', 'and', 'tape', 'e', '##ia', 'er', '##t', 'reel', 'and', 'tape', 'e', '##ia', 'mr', '##t', 'reel', 'and', 'tape', 'e', '##ia', 'dat', 'reel', 'and', 'tape', 'e', '##ia', 'dat', 'reel', 'and', 'tape', 'e', '##ia', 'dr', '##t', 'reel', 'and', 'tape', 'e', '##ia', 'dr', '##t', 'reel', 'and', 'tape', 'e', '##ia', 'dr', '##t', 'reel', 'and', 'tape', 'e', '##ia', 'dr', '##t', 'reel', 'and', 'tape', 'e', '##ia', 'dr', '##t', 'reel', 'and', 'tape', 'e', '##ia', 'er', '##t', 'reel', 'and', 'tape', 'e', '##ia', 'er', '##t', 'reel', 'and', 'tape', 'e', '##ia', 'er', '##t', 'reel', 'and', 'tape', 'e', '##ia', 'er', '##t', 'disc', '##lai', '##mer', 'notice', 'lit', '##tel', '##fus', '##e', 'products', 'are', 'not', 'designed', 'for', 'and', 'shall', 'not', 'used', 'for', 'any', 'purpose', 'including', 'without', 'limitation', 'automotive', 'military', 'aerospace', 'medical', 'life', 'saving', 'life', 'sustaining', 'nuclear', 'facility', 'applications', 'devices', 'intended', 'for', 'surgical', 'implant', 'into', 'the', 'body', 'any', 'other', 'application', 'which', 'the', 'failure', 'lack', 'desired', 'operation', 'the', 'product', 'may', 'result', 'personal', 'injury', 'death', 'property', 'damage', 'other', 'than', 'those', 'express', '##ly', 'set', 'forth', 'applicable', 'lit', '##tel', '##fus', '##e', 'product', 'documentation', 'warrant', '##ies', 'granted', 'lit', '##tel', '##fus', '##e', 'shall', 'deemed', 'void', 'for', 'products', 'used', 'for', 'any', 'purpose', 'not', 'express', '##ly', 'set', 'forth', 'applicable', 'lit', '##tel', '##fus', '##e', 'documentation', 'lit', '##tel', '##fus', '##e', 'shall', 'not', 'liable', 'for', 'any', 'claims', 'damages', 'arising', 'out', 'products', 'used', 'applications', 'not', 'express', '##ly', 'intended', 'lit', '##tel', '##fus', '##e', 'set', 'forth', 'applicable', 'lit', '##tel', '##fus', '##e', 'documentation', 'the', 'sale', 'and', 'use', 'lit', '##tel', '##fus', '##e', 'products', 'subject', 'lit', '##tel', '##fus', '##e', 'er', '##ms', 'and', 'conditions', 'sale', 'unless', 'otherwise', 'agreed', 'lit', '##tel', '##fus', '##e', 'information', 'furnished', 'believed', 'accurate', 'and', 'reliable', 'however', 'users', 'should', 'independently', 'evaluate', 'the', 'suit', '##ability', 'and', 'test', 'each', 'product', 'selected', 'for', 'their', 'own', 'applications', 'lit', '##tel', '##fus', '##e', 'products', 'are', 'not', 'designed', 'for', 'and', 'may', 'not', 'used', 'all', 'applications', 'read', 'complete', 'disc', '##lai', '##mer', 'notice', 'www', 'lit', '##tel', '##fus', '##e', 'com', 'disc', '##lai', '##mer', 'electronics', '[SEP]']\n",
      "1246\n",
      "['[CLS]', 'specification', 'customer', 'module', 'wi', '##cc', '##fl', 'approved', 'for', 'st', '##ome', '##r', 'use', 'only', 'pc', '##b', 'version', 'data', 'sales', 'app', '##rov', 'checked', 'prep', '##ar', 'issued', 'date', 'mod', '[UNK]', 'records', 'revision', 'doc', 'first', 'issue', '##version', 'date', 'revised', 'page', 'summary', 'first', 'issue', 'for', 'new', '##haven', 'graph', 'lcd', 'version', 'voltage', 'in', '##vert', '##er', 'cc', '##fl', 'for', 'cc', '##fl', 'back', '##light', 'version', 'v', '##dc', 'vr', '##ms', 'out', 'ro', '##hs', 'compliant', 'gene', '##r', 'this', 'specification', 'applied', 'wi', '##cc', '##fl', 'river', 'cc', '##fl', 'input', 'characteristics', 'parameter', 'symbol', 'min', 'no', '##m', 'max', 'unit', 'remark', 'input', 'voltage', 'vin', 'input', 'cu', '##rr', 'en', '##t', 'ii', '##n', 'vin', 'input', 'power', 'pin', 'vin', 'output', 'characteristics', 'parameter', 'symbol', 'min', 'no', '##m', 'max', 'unit', 'remark', 'output', 'voltage', 'vr', '##ms', 'vin', 'start', 'volta', '##g', 'tube', 'cu', '##rre', '##n', 'vin', 'working', 're', '##que', '##n', 'khz', 'life', 'time', 'hr', '##s', 'hr', '##s', 'con', '##tin', '##u', 'not', 'all', 'conditions', 'are', 'ambient', 'nl', '##ess', 'otherwise', 'specified', 'general', 'specifications', 'temperature', 'per', '##ating', 'temperature', 'storage', 'humidity', 'operating', 'humidity', 'storage', 'r', '##h', '##wi', '##cc', '##fl', 'dimension', 'pin', 'pin', 'pin', 'con', 'pin', 'assignment', 'int', '##put', 'connector', 'output', 'con', 'connector', 'pin', 'number', 'function', 'pin', 'pin', 'g', '##nd', 'pin', 'number', 'function', 'max', 'unit', 'the', 'non', 'specified', 'tolerance', 'dimension', 'max', 'sold', '##ering', 'pin', 'g', '##nd', 'g', '##nd', '##v', '[SEP]']\n",
      "204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer =  BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # print(len(tokens['input_ids'][0]))\n",
    "\n",
    "valid_docs = 0\n",
    "for text in texts[:2]:\n",
    "    tokens = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "\n",
    "            truncation=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "    print(tokenizer.convert_ids_to_tokens(tokens['input_ids'][0]))\n",
    "    print(len(tokenizer.convert_ids_to_tokens(tokens['input_ids'][0])))\n",
    "    if len(tokens['input_ids'][0]) < 512:\n",
    "        valid_docs += 1\n",
    "\n",
    "valid_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Replace numbers with optional decimal part with a space\n",
    "    text = re.sub(r'\\d+(\\.\\d+)?', ' ', text)\n",
    "    \n",
    "    # Replace multiple newlines with a single newline\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    \n",
    "    # Replace any non-word characters (except whitespace, periods, commas, and dashes) with a space\n",
    "    text = re.sub(r'[^\\w\\s.,-]', ' ', text)\n",
    "    \n",
    "    # Remove spaces before punctuation marks (., -)\n",
    "    text = re.sub(r'\\s+([.,-])', r'\\1', text)\n",
    "    \n",
    "    # Replace multiple spaces with a single space and trim leading/trailing spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Replace underscores and spaces with a single space\n",
    "    text = re.sub(r'[_\\s]+', ' ', text)\n",
    "\n",
    "    # text = re.sub(r'[#+\\*]', ' ', text)\n",
    "    \n",
    "    # Replace dashes and spaces with a single space\n",
    "    text = re.sub(r'[-\\s]+', ' ', text)\n",
    "\n",
    "    text = re.sub(r'[\\.\\,]+', ' ', text )\n",
    "\n",
    "    text = re.sub(r'\\b\\w{1,2}\\b', ' ', text)\n",
    "    \n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "#     text = re.sub(r'\\W+', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "\n",
    "    # Remove extra spaces that may be left behind\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    cleaned_text = cleaned_text.replace('#', '')\n",
    "\n",
    "\n",
    "    \n",
    "    return cleaned_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/guest1/Desktop/parspec-assignment/data/train_texts/cable_119.txt', 'r') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = clean_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_ in ct.split():\n",
    "    if '#' in text_:\n",
    "        print(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tms coax www timesmicrowave com times microw ave systems lmr ideal jumper assemblies wireless communications systems short antenna feeder runs application wll gps lmr wlan wisp wimax scada mobile antennas requiring easily routed low loss cable electrical specifications performance property units metric velocity propagation dielectric constant time delay impedance ohms capacitance inductance shielding effectiveness resistance inner conductor ohms outer conductor ohms voltage withstand volts jacket spark volts rms peak power mechanical specifications performance property units metric bend radius installation bend radius repeated bending moment weight tensile strength flat plate crush lmr flexible low loss communications coax environmental specifications performance property installation temperature range storage temperature range operating temperature range construction specifications description material inner conductor solid bccal dielectric foam outer conductor aluminum tape overall braid tinned copper jacket see table part description stock part number application jacket color code lmr outdoor black lmr outdoor watertight black lmr indoor outdoor riser cmr frpe black lmr pvc indoor outdoor riser cmr frpvc black lmr pvc general purpose pvc black lmr pvc general purpose pvc white tms coax www timesmicrowave com times microw ave systems attenuation frequency typical attenuation per feet frequency mhz lmr calculate attenuation fmhz fmhz interactive calculator available http www timesmicrowave com cable calculators attenuation vswr ambient power vswr ambient inner conductor sea level dry air atmospheric pressure solar loading frequency mhz attenuation attenuation avg power tms coax www timesmicrowave com times microw ave systems lmr lmr flexible low loss communications coax nmc nfc inner outer finish part stock vswr coupling contact contact body length width weight interface description number code freq ghz nut attach attach pin eia flange eia spring finger clamp din female straight jack solder clamp din straight plug hex spring finger crimp din straight plug hex solder crimp din straight plug hex solder clamp male right angle hex spring finger crimp din right angle hex solder crimp din straight jack hex spring finger crimp male straight plug hnmc knurl solder clamp male straight plug lcm hex solder clamp female straight jack solder crimp female straight jack spring finger crimp female bulkhead jack spring finger crimp female bulkhead jack solder crimp female bulkhead jack nfc solder clamp male straight plug nmk knurl spring finger crimp male straight plug nmc hex knurl spring finger clamp male straight plug nmh hex knurl spring finger crimp male straight plug nmh hex knurl solder crimp male right angle nmh hex spring finger crimp male right angle nmh hex solder crimp male straight plug nmh hex solder crimp bnc male right angle knurl solder crimp tnc male straight plug hex knurl solder crimp tnc male straight plug hex knurl spring finger crimp tnc male reverse polarity knurl spring finger crimp tnc male reverse polarity knurl spring finger crimp tnc male reverse polarity knurl solder crimp tnc male right angle hex knurl solder crimp tnc female reverse polarity spring finger crimp tnc female reverse polarity knurl solder crimp uhf male straight plug knurl spring finger crimp uhf male straight plug umc knurl solder clamp finsh metals nickel silver gold stainless steel alballoy vswr spec based foot cable connector pair available bulk pack nmk eia hnmc lcm nmh nmh nmh nmh nmh connectors tms coax www timesmicrowave com times microw ave systems lmr umc gst dbt cst cct cst part stock type number code description ground kit standard grounding kit hoisting grip split laced type cold shrink cable antenna junction cold shrink lmr junction cold shrink lmr junction hanger blocks dual cable support block kit stand entry port cushion three cables snap hangers snap hangers kit hanger block supporting hardware complete range supporting hardware adapters available weather proof boot ipb lmr male boot suitable type tnc bnc weather proof boot ipb lmr female boot suitable type tnc bnc weather seal boots wsb weather seal strain relief boot use popular lmr series connectors tcs tgk tsh hanger support hardware part stock type number code description crimp tool crimp handle crimp dies hex dies crimp rings crimp rings connectors pkg strip tool cst combination prep tool lmr crimp clamp style connectors crimp tool crimp tool lmr connectors replacement blades replacement blades strip tools deburr tool dbt removes center conductor rough edges midspan strip tool gst ground strap attachment wrench box wrench required nmc cutting tool cct cable end flush cut tool replacement blade replacement blade cutting tool replacement blade kit cst replacement blade kit cst strip tools tool kit tool kit lmr crimp clamp connectors includes cct cst tool pouch install tools hardware accessories ipb ipb wsb'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guest1/opt/miniconda3/envs/parspec/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "def chunk_text(document_text, max_token_length=256, overlap=150):\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    tokens = tokenizer.tokenize(document_text)\n",
    "    \n",
    "    chunks = []\n",
    "    start = 0\n",
    "    total_tokens = len(tokens)\n",
    "\n",
    "    while start < total_tokens:\n",
    "        end = min(start + max_token_length, total_tokens)\n",
    "        chunk = tokens[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap  # Slide the window with overlap\n",
    "\n",
    "    # Print length of each chunk for verification\n",
    "    for chunk in chunks:\n",
    "        print(len(chunk))\n",
    "\n",
    "    # Convert chunks back to text\n",
    "    chunks_text = [tokenizer.convert_tokens_to_string(chunk) for chunk in chunks]\n",
    "    \n",
    "    return chunks_text\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# document_text = ct  # Replace with your document text\n",
    "chunked_text = chunk_text(ct)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "187\n",
      "\n",
      "Chunk 2:\n",
      "169\n",
      "\n",
      "Chunk 3:\n",
      "149\n",
      "\n",
      "Chunk 4:\n",
      "182\n",
      "\n",
      "Chunk 5:\n",
      "90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(chunked_text):\n",
    "    print(f\"Chunk {i + 1}:\")\n",
    "    print(len(chunk.split()))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunked_text[2].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    # tokens = tokenizer.encode_plus(\n",
    "    #         document_text,\n",
    "    #         add_special_tokens=True,\n",
    "    #         truncation=False,\n",
    "    #         return_tensors='pt'\n",
    "    #     )\n",
    "    \n",
    "    # chunks = []\n",
    "\n",
    "    # start = 0\n",
    "    # total_tokens = len(tokens['input_ids'][0])\n",
    "    # print(total_tokens)\n",
    "\n",
    "    # if start < total_tokens:\n",
    "    #     end = min(start + 256, total_tokens)\n",
    "    #     # print(start,end)\n",
    "    #     chunk = tokens['input_ids'][0][start:end].tolist()\n",
    "    # #     # print(chunk)\n",
    "    #     chunks.append(chunk)\n",
    "        \n",
    "    # #     # Move the start position forward by the difference between end and start\n",
    "    #     start = end - overlap\n",
    "    #     print(start)\n",
    "    # #     if start >= total_tokens:\n",
    "    # #         break  # Break the loop if start exceeds the total number of tokens\n",
    "\n",
    "    # # Print length of each chunk for verification\n",
    "    # for chunk in chunks:\n",
    "    #     print(len(chunk))\n",
    "\n",
    "    # # Convert chunks back to text\n",
    "    # chunks_text = [tokenizer.convert_ids_to_tokens(chunk) for chunk in chunks]\n",
    "    # print(chunks_text)\n",
    "    # return chunks_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activeloop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
